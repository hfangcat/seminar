<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Past seminars on KTH ML Seminars</title>
    <link>https://kth-ml-seminars.netlify.app/tags/past-seminars/</link>
    <description>Recent content in Past seminars on KTH ML Seminars</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© Copyright notice</copyright>
    <lastBuildDate>Tue, 13 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://kth-ml-seminars.netlify.app/tags/past-seminars/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mostafa Dehghani: Scaling up Vision Models with Transformers</title>
      <link>https://kth-ml-seminars.netlify.app/posts/post-1/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://kth-ml-seminars.netlify.app/posts/post-1/</guid>
      <description>Title: Scaling up Vision Models with Transformers
Speaker: Mostafa Dehghani, Google Brain
Date and Time: Tuesday, April 13, 1-2 pm
Place: Zoom Meeting
Meeting ID: 698 1002 6609 Pass code: 983918
Abstract: While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place.</description>
    </item>
    
    <item>
      <title>Alyosha Efros: The Revolution Will Not Be Supervised</title>
      <link>https://kth-ml-seminars.netlify.app/posts/post-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kth-ml-seminars.netlify.app/posts/post-6/</guid>
      <description>Title: The Revolution Will Not Be Supervised
Speaker: Alyosha Efros, University of California Berkeley
Date and Time: 2019
Place: Room 304, Teknikringen 14
Abstract: Computer vision has made impressive gains through the use of deep learning models trained with large-scale labeled data. However, labels require expertise and curation and are expensive to collect. Worse, semantic supervision often leads to models that can &amp;ldquo;cheat&amp;rdquo;. Can one discover useful visual representations without the use of explicitly curated labels?</description>
    </item>
    
    <item>
      <title>Daphna Weinshall</title>
      <link>https://kth-ml-seminars.netlify.app/posts/post-7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kth-ml-seminars.netlify.app/posts/post-7/</guid>
      <description>Title:
Speaker: Daphna Weinshall, Hebrew University, Jerusalem
Date and Time: 2019
Place: Room 525, Teknikringen 14
Abstract:
Bio:</description>
    </item>
    
  </channel>
</rss>
